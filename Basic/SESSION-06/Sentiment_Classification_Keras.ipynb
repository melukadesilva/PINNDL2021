{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LWzdAKps6by"
      },
      "source": [
        "### Original tutorial:## Example from: https://www.tensorflow.org/tutorials/text/text_classification_rnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nFm02fges3_D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2WPcwS6-tBpw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXrVkaSZtLLB",
        "outputId": "9e01e57d-4256-425e-ac1a-28ba63f064a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Download the imdb review dataset. This dataset has a binary label\n",
        "## for each text input. Label beign the move is good or bad (positive or negative)\n",
        "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
        "                          as_supervised=True)\n",
        "## Split the dataset into train and test set\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "## Check the data types of inputs and output\n",
        "train_dataset.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-ySQnlOtNe2",
        "outputId": "62d0d94f-3fdf-4968-f770-3e4525417355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
            "label:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-22 13:53:13.601339: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        }
      ],
      "source": [
        "## view one input output pair\n",
        "for example, label in train_dataset.take(1):\n",
        "  print('text: ', example.numpy())\n",
        "  print('label: ', label.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RS0ETQlCtQPT"
      },
      "outputs": [],
      "source": [
        "len(train_dataset)\n",
        "## Buffer size should be equal or greater than the size of train dataset for randomly suffling\n",
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "t8w4xgpjtS4K"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL-oLKNotVdj",
        "outputId": "9f079d89-1ff3-4675-c27b-2987614befa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "dataset = tf.data.Dataset.range(3)\n",
        "dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
        "dataset = dataset.repeat(2)\n",
        "for eg in dataset:\n",
        "    print(eg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MQBwFHGtZ68",
        "outputId": "8eda8a50-7234-450e-d0c8-738fe2a0f47e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "texts:  [b'Repugnant Bronson thriller. Unfortunately, it\\'s technically good and I gave it 4/10, but it\\'s so utterly vile that it would be inconceivable to call it \"entertainment\". Far more disturbing than a typical slasher film.'\n",
            " b\"I've watched this movie twice now on DVD, and both times it didn't fail to impress me with its unique impartial attitude. It seems more like a depiction of reality than most other Hollywood fare, especially on a topic that is still hotly discussed. Even though it sticks closely with the southern viewpoint, it doesn't fail to question it, and in the end the only sentence passed is that the war is lost, not matter what, and cruelty is a common denominator.<br /><br />What really makes this movie outstanding is the refusal to over-dramatize. Nowadays truly good movies (in a nutshell) are few and far apart, with mainstream fare being enjoyable (if you don't have high expectations), but terribly commercially spirited. I think this movie comes off as a truly good movie (without being a masterpiece), because it sticks to itself, and gives the viewer a chance to watch and analyze it, instead of wanting to bombard him with effect and emotion to blot out his intelligence. This movie is cool, observant, and generally light-handed in its judgement, which is GOOD.<br /><br />The story has its flaws, especially Jewel's Character comes off doubtfully, but then again the situation at the time was so chaotic, that for a young widow it might have been only logical to somehow get back into a normal life, even by liberally taking each next guy. Still she doesn't come off as weak, in fact I think she's one of the stronger characters, she's always in control of the relationships, with the men just tagging. And I take it very gratefully that she's not a weeping widow. I believe in the 19th century death of a loved one was something a lot more normal than now. You could die so easily of even minor illnesses and injuries, so the prospect of of someone dying, while surely causing grief, didn't traumatise people like it does now. People didn't seem to build shrines about their lost ones like they do now, and I like that attitude.<br /><br />My recommendation is for intelligent people to watch this movie, if they are in the mood for something different than the usual hollywood fare. Don't watch if if you want non-stop action or heart-renting emotion.\"\n",
            " b'I think it took a lot of guts for her to come forward like that. It is unfortunate that when a celebrity suffers that is what helps people most. But, in her case, what she did was remarkable. I have been in the mental health field for five years and I think it is great that mental illness is not a terrible word anymore and I believe she helped. I always thought she was great and always will. I am glad that she wrote this book and that the movie was made. She is a remarkable lady and I hope she continues to act. She has been through a lot and has faced it. I would really love to see her work more with children, especially child actors. Her ordeal should not have happened and I think she would be wonderful as a mentor to young people. The movie was so moving to me that I was very touched. Suffering a TBI which brought the onset of my disorder and having PTSD, it is good to know that someone has the courage enough to display her life as she did. I believe it helped this nation and people in general realize that there are others like them and that there is help. Thank you Ms. Duke, or Anna, which ever you prefer.']\n",
            "\n",
            "labels:  [0 1 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-22 13:53:13.835594: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        }
      ],
      "source": [
        "## Take one batch and view first 3 input text and output labels\n",
        "for example, label in train_dataset.take(1):\n",
        "  print('texts: ', example.numpy()[:3])\n",
        "  print()\n",
        "  print('labels: ', label.numpy()[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pJKXSXWOtmBI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-22 13:53:13.884045: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "## Vocabulary size defines the number of unique words we must keep for encoding data through tokenization\n",
        "## any word that is out of the vocabulary will be annotated as a UKN\n",
        "VOCAB_SIZE=1000\n",
        "## The TextVectorization preprocessor converts the sentences into tokens\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxvA5zIVto8f",
        "outputId": "7848633e-2426-4e94-cb37-7e08b3f32eb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
              "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n",
              "      dtype='<U14')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## view the first 20 words of the vocabulary\n",
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc7sItn8trrY",
        "outputId": "4aeb0ed3-d112-42ae-fe03-acfd78cd8be3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  1,   1, 773, ...,   0,   0,   0],\n",
              "       [195, 284,  11, ...,   0,   0,   0],\n",
              "       [ 10, 103,   9, ...,   0,   0,   0]])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## view the tokens of the first 3 examples of the 1st batch\n",
        "encoded_example = encoder(example)[:3].numpy()\n",
        "encoded_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snK1lkkPtt3_",
        "outputId": "86f5346c-dcba-4e5f-d4a4-28d54d844092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  b'Repugnant Bronson thriller. Unfortunately, it\\'s technically good and I gave it 4/10, but it\\'s so utterly vile that it would be inconceivable to call it \"entertainment\". Far more disturbing than a typical slasher film.'\n",
            "Round-trip:  [UNK] [UNK] thriller unfortunately its [UNK] good and i gave it [UNK] but its so [UNK] [UNK] that it would be [UNK] to call it entertainment far more [UNK] than a typical [UNK] film                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
            "\n",
            "Original:  b\"I've watched this movie twice now on DVD, and both times it didn't fail to impress me with its unique impartial attitude. It seems more like a depiction of reality than most other Hollywood fare, especially on a topic that is still hotly discussed. Even though it sticks closely with the southern viewpoint, it doesn't fail to question it, and in the end the only sentence passed is that the war is lost, not matter what, and cruelty is a common denominator.<br /><br />What really makes this movie outstanding is the refusal to over-dramatize. Nowadays truly good movies (in a nutshell) are few and far apart, with mainstream fare being enjoyable (if you don't have high expectations), but terribly commercially spirited. I think this movie comes off as a truly good movie (without being a masterpiece), because it sticks to itself, and gives the viewer a chance to watch and analyze it, instead of wanting to bombard him with effect and emotion to blot out his intelligence. This movie is cool, observant, and generally light-handed in its judgement, which is GOOD.<br /><br />The story has its flaws, especially Jewel's Character comes off doubtfully, but then again the situation at the time was so chaotic, that for a young widow it might have been only logical to somehow get back into a normal life, even by liberally taking each next guy. Still she doesn't come off as weak, in fact I think she's one of the stronger characters, she's always in control of the relationships, with the men just tagging. And I take it very gratefully that she's not a weeping widow. I believe in the 19th century death of a loved one was something a lot more normal than now. You could die so easily of even minor illnesses and injuries, so the prospect of of someone dying, while surely causing grief, didn't traumatise people like it does now. People didn't seem to build shrines about their lost ones like they do now, and I like that attitude.<br /><br />My recommendation is for intelligent people to watch this movie, if they are in the mood for something different than the usual hollywood fare. Don't watch if if you want non-stop action or heart-renting emotion.\"\n",
            "Round-trip:  ive watched this movie [UNK] now on dvd and both times it didnt [UNK] to [UNK] me with its unique [UNK] [UNK] it seems more like a [UNK] of reality than most other hollywood [UNK] especially on a [UNK] that is still [UNK] [UNK] even though it [UNK] [UNK] with the [UNK] [UNK] it doesnt [UNK] to question it and in the end the only [UNK] [UNK] is that the war is lost not matter what and [UNK] is a [UNK] [UNK] br what really makes this movie [UNK] is the [UNK] to [UNK] [UNK] truly good movies in a [UNK] are few and far apart with [UNK] [UNK] being enjoyable if you dont have high [UNK] but [UNK] [UNK] [UNK] i think this movie comes off as a truly good movie without being a [UNK] because it [UNK] to itself and gives the viewer a chance to watch and [UNK] it instead of [UNK] to [UNK] him with effect and [UNK] to [UNK] out his [UNK] this movie is cool [UNK] and [UNK] [UNK] in its [UNK] which is [UNK] br the story has its [UNK] especially [UNK] character comes off [UNK] but then again the situation at the time was so [UNK] that for a young [UNK] it might have been only [UNK] to somehow get back into a [UNK] life even by [UNK] taking each next guy still she doesnt come off as weak in fact i think shes one of the [UNK] characters shes always in [UNK] of the [UNK] with the men just [UNK] and i take it very [UNK] that shes not a [UNK] [UNK] i believe in the [UNK] [UNK] death of a loved one was something a lot more [UNK] than now you could die so easily of even [UNK] [UNK] and [UNK] so the [UNK] of of someone [UNK] while [UNK] [UNK] [UNK] didnt [UNK] people like it does now people didnt seem to [UNK] [UNK] about their lost ones like they do now and i like that [UNK] br my [UNK] is for [UNK] people to watch this movie if they are in the [UNK] for something different than the usual hollywood [UNK] dont watch if if you want [UNK] action or [UNK] [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
            "\n",
            "Original:  b'I think it took a lot of guts for her to come forward like that. It is unfortunate that when a celebrity suffers that is what helps people most. But, in her case, what she did was remarkable. I have been in the mental health field for five years and I think it is great that mental illness is not a terrible word anymore and I believe she helped. I always thought she was great and always will. I am glad that she wrote this book and that the movie was made. She is a remarkable lady and I hope she continues to act. She has been through a lot and has faced it. I would really love to see her work more with children, especially child actors. Her ordeal should not have happened and I think she would be wonderful as a mentor to young people. The movie was so moving to me that I was very touched. Suffering a TBI which brought the onset of my disorder and having PTSD, it is good to know that someone has the courage enough to display her life as she did. I believe it helped this nation and people in general realize that there are others like them and that there is help. Thank you Ms. Duke, or Anna, which ever you prefer.'\n",
            "Round-trip:  i think it took a lot of [UNK] for her to come forward like that it is [UNK] that when a [UNK] [UNK] that is what [UNK] people most but in her case what she did was [UNK] i have been in the [UNK] [UNK] [UNK] for five years and i think it is great that [UNK] [UNK] is not a terrible word [UNK] and i believe she [UNK] i always thought she was great and always will i am [UNK] that she [UNK] this book and that the movie was made she is a [UNK] lady and i hope she [UNK] to act she has been through a lot and has [UNK] it i would really love to see her work more with children especially child actors her [UNK] should not have happened and i think she would be wonderful as a [UNK] to young people the movie was so moving to me that i was very [UNK] [UNK] a [UNK] which brought the [UNK] of my [UNK] and having [UNK] it is good to know that someone has the [UNK] enough to [UNK] her life as she did i believe it [UNK] this [UNK] and people in general realize that there are others like them and that there is help [UNK] you [UNK] [UNK] or [UNK] which ever you [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for n in range(3):\n",
        "  print(\"Original: \", example[n].numpy())\n",
        "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TcS-fATCtx6B"
      },
      "outputs": [],
      "source": [
        "## The sentiment classification model architecture:\n",
        "model = tf.keras.Sequential([\n",
        "    encoder, ## Tokenisation layer that converts a batch of input text to tokens with int values\n",
        "    tf.keras.layers.Embedding( ## A trainable layer that learns to embbed the tokens to a real value distribution\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw0OP8ILt3QY",
        "outputId": "e8828372-8f1b-49a5-9b8f-924835916dc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-22 13:53:16.097769: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
            "2021-11-22 13:53:16.221526: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
            "2021-11-22 13:53:16.260129: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.00463221]\n",
            "(None, None, 64)\n"
          ]
        }
      ],
      "source": [
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions[0])\n",
        "print(model.layers[1].output_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "L6ZMprxCt9y1"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "pKuP24fPt_nE",
        "outputId": "9faada69-7950-4f70-b42f-557639c50217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-22 13:53:18.116337: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
            "2021-11-22 13:53:18.427679: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
            "2021-11-22 13:53:18.517368: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
            "2021-11-22 13:53:20.975437: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
            "2021-11-22 13:53:21.076547: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  3/391 [..............................] - ETA: 1:01:23 - loss: 0.6932 - accuracy: 0.4896"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/ty/pxb5sqj175xg9rl8xpmdxlkc0000gn/T/ipykernel_2353/269628942.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(train_dataset, epochs=10,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     validation_steps=30)\n",
            "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model.fit(train_dataset, epochs=10,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=test_dataset, \n",
        "                    validation_steps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvjGMkVVuCXS"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTNa4epruEqt"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(1,2,1)\n",
        "plot_graphs(history, 'accuracy')\n",
        "plt.ylim(None,1)\n",
        "plt.subplot(1,2,2)\n",
        "plot_graphs(history, 'loss')\n",
        "plt.ylim(0,None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlgbnhCXuHU0"
      },
      "outputs": [],
      "source": [
        "## do a prediction\n",
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BeeHoZzuMe5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Sentiment_Classification_Keras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
